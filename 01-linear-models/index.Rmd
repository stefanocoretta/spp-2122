---
title: "Linear models"
subtitle: "<br><br>Modelling binary outcomes"
author: "Stefano Coretta"
institute: "University of Edinburgh"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css:
      - default
      - ../ipa-fonts.css
      - ../custom.css
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      beforeInit: "../macros.js"
      ratio: 16:9
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, dpi = 300, fig.width = 7, fig.height = 5, out.height = "500px", fig.align = "center")
knitr::opts_knit$set(root.dir = here::here())
options(htmltools.dir.version = FALSE)
library(tidyverse)
theme_set(theme_minimal(base_size = 16))
options(ggplot2.discrete.colour = RColorBrewer::brewer.pal(5, "Dark2"))
library(xaringanExtra)
use_xaringan_extra(c("panelset", "tachyons"))
library(ggeffects)
options(show.signif.stars = FALSE)
library(lme4)
library(broom.mixed)
```

```{r read-data}
polite <- read_csv("01-linear-models/polite.csv") %>%
  mutate(
    attitude = factor(attitude, levels = c("inf", "pol")),
    musicstudent = factor(musicstudent, levels = c("no", "yes"))
  )

sanker2020 <- read_csv("01-linear-models/sanker2020.csv") %>%
  mutate(OrigCoda = factor(OrigCoda, levels = c("voiceless", "voiced")))
```



class: center middle

![:scale 40%](../img/charlesdeluvio-D44HIk-qsvI-unsplash.jpg)

???

Photo by <a href="https://unsplash.com/@charlesdeluvio?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">charlesdeluvio</a> on <a href="https://unsplash.com/s/photos/sad-puppy?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a>
  
---

class: center middle

![:scale 90%](../img/joe-caione-qO-PIF84Vxg-unsplash.jpg)

???

Photo by <a href="https://unsplash.com/@joeyc?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Joe Caione</a> on <a href="https://unsplash.com/s/photos/happy-puppy?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a>

---

# Exercise 1: Articulation rate and politeness

- Data from Winter and Grawunder 2012.

- 16 speakers of Korean recorded in Germany.

- Informal vs polite (formal) speech.

- 6 of those speakers were music students.


???

Bodo Winter, Sven Grawunder. 2012. The phonetic profile of Korean formal and informal speech registers, Journal of Phonetics 40(6). 808-815. https://doi.org/10.1016/j.wocn.2012.08.006

---

# Exercise 1: Articulation rate and politeness

```{r art-rate, echo=TRUE}
art_lm_1 <- lmer(
  articulation_rate ~
    attitude *
    musicstudent +
    (attitude|subject),
  data = polite
)

tidy(art_lm_1, effects = "fixed")
```

---

# Exercise 1: Articulation rate and politeness

```{r art-rate-plot}
ggpredict(art_lm_1, terms = c("attitude", "musicstudent")) %>%
  plot() +
  theme(text = element_text(size = 20))
```

---

# Exercise 2: Mean f0 and politeness

```{r f0, echo=TRUE}
f0_lm_1 <- lmer(
  f0mn ~
    attitude *
    years_in_ger +
    # random slope by attitude leads to singular fit...
    (1|subject),
  data = polite
)

tidy(f0_lm_1, effects = "fixed")
```

---

# Exercise 2: Mean f0 and politeness

```{r f0-plot}
ggpredict(f0_lm_1, terms = c("attitude", "years_in_ger [1,3,6,9]")) %>%
  plot() +
  theme(text = element_text(size = 20))
```

---

class: center middle reverse

# Articulation rate and mean f0 are .green[continuous] (numeric) outcome variables...

---

class: center middle reverse

# But .green[binary outcomes], like yes/no, correct/incorrect, true/false are not continuous!

---

class: center middle

.f1.link.dim.br3.ph3.dib.white.bg-purple[
[.white[Probability distributions]](https://seeing-theory.brown.edu/probability-distributions/index.html#section2)
]

---

# Binary outcome: Bernoulli distribution

.center[
<a title="Niklaus Bernoulli (1662-1716), Public domain, via Wikimedia Commons" href="https://commons.wikimedia.org/wiki/File:Jakob_Bernoulli.jpg"><img width="512" alt="Jakob Bernoulli" src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/19/Jakob_Bernoulli.jpg/512px-Jakob_Bernoulli.jpg"></a>
]

---

# Binary outcome: Perception of vowel duration

- Data from Sanker 2020.

- Participants listen to words and have to say if the vowel is short (0) or long (1).

- Vowel duration was manipulated in 10 steps of about 15 ms each.

- Furthermore, vowel splices come either from words with a final voiceless stop or from words with a final voiced stop.


???

Sanker, C. (2020). A perceptual pathway for voicing-conditioned vowel duration. Laboratory Phonology, 11(1).

---

# Binary outcome: Perception of vowel duration

```{r sanker-lm-1, echo=TRUE}
sanker_lm_1 <- glmer(
  Longresps ~
    durationstep +
    (durationstep | participant),
  data = sanker2020,
  family = binomial
)

tidy(sanker_lm_1, effects = "fixed")
```

---

# Do you notice something weird in the output?

```{r sanker-lm-1-2, echo=TRUE}
sanker_lm_1 <- glmer(
  Longresps ~
    durationstep +
    (durationstep | participant),
  data = sanker2020,
  family = binomial
)

tidy(sanker_lm_1, effects = "fixed")
```

---

class: right middle inverse

# The estimates are in .green[log-odds] (or simply logs).

# To make sense of them we need to .green[transform] them.

---

# Logistic function

We can transform logs into probabilities with the logistic function `plogis()`

```{r plogis}
# What is the probability when log-odds = 0?
plogis(0)

# What is the probability when log-odds = 1?
plogis(1)
```

--

<br>

Now try different positive and negative numbers with `plogis()`.

---

# From log-odds to probabilities

```{r p-log-odds}
dots <- tibble(
  p = seq(0.1, 0.9, by = 0.1),
  log_odds = qlogis(p)
)

tibble(
  p = seq(0, 1, by = 0.001),
  log_odds = qlogis(p)
) %>%
  ggplot(aes(log_odds, p)) +
  geom_hline(yintercept = 0.5, linetype = "dashed") +
  geom_hline(yintercept = 0, colour = "#8856a7", size = 1) +
  geom_hline(yintercept = 1, colour = "#8856a7", size = 1) +
  geom_vline(xintercept = 0, alpha = 0.5) +
  geom_line(size = 2) +
  geom_point(data = dots, size = 4) +
  scale_x_continuous(breaks = seq(-6, 6, by = 2), minor_breaks = NULL) +
  scale_y_continuous(breaks = seq(0, 1, by = 0.1), minor_breaks = NULL) +
  labs(
    title = "Correspondence between log-odds and probabilities",
    x = "log-odds",
    y = "probability"
  )
```

---

# Binary outcome: Perception of vowel duration

```{r sanker-lm-1-3, echo=TRUE}
tidy(sanker_lm_1, effects = "fixed")
```

---

# Binary outcome: Perception of vowel duration

```{r sanker-lm-1-plot, message=FALSE, warning=FALSE}
ggpredict(sanker_lm_1, terms = "durationstep") %>%
  plot()
```

---

# Binary outcome: Perception of vowel duration

```{r sanker-lm-2, echo=TRUE}
sanker_lm_2 <- glmer(
  Longresps ~
    durationstep *
    OrigCoda +
    # random slope by OrigCoda leads to singular fit/non-convergence...
    (durationstep | participant),
  data = sanker2020,
  family = binomial
)

tidy(sanker_lm_2, effects = "fixed")
```


---

# Binary outcome: Perception of vowel duration

```{r sanker-lm-2-plot}
ggpredict(sanker_lm_2, terms = c("durationstep", "OrigCoda")) %>%
  plot()
```

---

# Exercise 3: Perception of place of articulation in Pitjantjatjara

- You create a set of stimuli by manipulating the Centre of Gravity of the burst of a stop to vary between 1 kHz and 4 kHz, in steps of 500 Hz (6 steps).

- Your participants are native speakers of Pitjantjatjara (Central Australian), which has five stop places of articulation /p t ʈ c k/.

- You ask them to identify what they hear as either /ʈ/ (0) or /c/ (1).

- A linear model with a Bernoulli distribution for the response returns an intercept = -2.5 and an estimated effect of CoG step = 0.8.

Calculate with the `plogis()` function:

- The average probability of a /c/ response at CoG = 1000.

- The average probability of a /c/ response at CoG = 2500.

- The average probability of a /c/ response at CoG = 3750.

---

class: center middle

![:scale 90%](../img/joe-caione-qO-PIF84Vxg-unsplash.jpg)

???

Photo by <a href="https://unsplash.com/@joeyc?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Joe Caione</a> on <a href="https://unsplash.com/s/photos/happy-puppy?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a>

---

class: center middle inverse

# THE END

---

# BTW, the normal distribution ain't that normal

.center[
![:scale 40%](../img/skew-you.jpeg)
]

---

class: center middle inverse

# EXTRA

---

# Exponential function

We can transform log-odds into odds with `exp()`.

```{r log-exp, echo=TRUE}
# What is the exponential function at log = 0?
exp(0)

# What is the exponential function at log = 1?
exp(1)
```

---

# Exponential function

Now try different numbers with `exp()`.

You can transform back the exponentiated number with the `log()` function.

```{r logs, echo=TRUE}
# With log = 0
# exp(0) = 1
exp(0)

# With exp = 1
# log(1) = 0
log(1)
```


---

# From log-odds to odds

```{r log-odds}
tibble(
  log_odds = seq(-2, 2, by = 0.001),
  odds = exp(log_odds)
) %>%
  ggplot(aes(log_odds, odds)) +
  geom_vline(xintercept = 0, alpha = 0.5) +
  geom_hline(yintercept = 1, linetype = "dashed") +
  geom_hline(yintercept = 0, size = 1, colour = "#8856a7") +
  geom_line(size = 2) +
  geom_point(x = 0, y = 1, size = 4) +
  scale_y_continuous(breaks = seq(0, 6, by = 1), minor_breaks = NULL) +
  labs(
    title = "Correspondence between log-odds and odds",
    subtitle = "odds = exp(log-odds)",
    x = "log-odds",
    y = "odds"
  )
```
